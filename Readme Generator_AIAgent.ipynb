{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgQ9lK0tkMuS",
        "outputId": "5b68dae3-02b0-43a3-d36d-504d9d3c3cc9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Requirement already satisfied: litellm in /usr/local/lib/python3.11/dist-packages (1.74.8)',\n",
              " 'Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.15)',\n",
              " 'Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.2.1)',\n",
              " 'Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.28.1)',\n",
              " 'Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.7.0)',\n",
              " 'Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.6)',\n",
              " 'Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.25.0)',\n",
              " 'Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.97.0)',\n",
              " 'Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.11.7)',\n",
              " 'Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.1.1)',\n",
              " 'Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.9.0)',\n",
              " 'Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.2)',\n",
              " 'Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (2.6.1)',\n",
              " 'Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (1.4.0)',\n",
              " 'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (25.3.0)',\n",
              " 'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (1.7.0)',\n",
              " 'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (6.6.3)',\n",
              " 'Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (0.3.2)',\n",
              " 'Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10->litellm) (1.20.1)',\n",
              " 'Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (4.9.0)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (2025.7.14)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)',\n",
              " 'Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.10)',\n",
              " 'Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)',\n",
              " 'Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)',\n",
              " 'Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)',\n",
              " 'Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.4.1)',\n",
              " 'Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)',\n",
              " 'Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.26.0)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (1.9.0)',\n",
              " 'Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (0.10.0)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (1.3.1)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (4.67.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm) (4.14.1)',\n",
              " 'Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)',\n",
              " 'Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.33.2)',\n",
              " 'Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.1)',\n",
              " 'Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)',\n",
              " 'Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)',\n",
              " 'Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.33.4)',\n",
              " 'Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.18.0)',\n",
              " 'Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2025.7.0)',\n",
              " 'Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (25.0)',\n",
              " 'Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)',\n",
              " 'Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (1.1.5)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.2)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.5.0)']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!!pip install litellm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnXPysZGg-XL",
        "outputId": "fe321f68-4bc8-445d-e3e0-d380694fdc49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"write_readme\", \"args\": {\"content\": \"README.md\"}}\n",
            "Action Result: {'tool_executed': True, 'result': 'README.md file created successfully.', 'timestamp': '2025-07-25T11:40:25+0000'}\n",
            "[{'type': 'user', 'content': 'Write readme.md file, which includes the summary of all the python files'}, {'type': 'assistant', 'content': '{\"tool\": \"write_readme\", \"args\": {\"content\": \"README.md\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"README.md file created successfully.\", \"timestamp\": \"2025-07-25T11:40:25+0000\"}'}]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "from litellm import completion\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Callable, Dict, Any\n",
        "\n",
        "GROQ_API_KEY = \"API KEY\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Prompt:\n",
        "    messages: List[Dict] = field(default_factory=list)\n",
        "    tools: List[Dict] = field(default_factory=list)\n",
        "    metadata: dict = field(default_factory=dict)\n",
        "\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "\n",
        "    messages = prompt.messages\n",
        "    tools = prompt.tools\n",
        "\n",
        "    result = None\n",
        "\n",
        "    if not tools:\n",
        "        response = completion(\n",
        "            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "            messages=messages,\n",
        "            max_tokens=1024,\n",
        "            api_base=\"https://api.groq.com/openai/v1\",\n",
        "            api_key=GROQ_API_KEY1\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "    else:\n",
        "        response = completion(\n",
        "            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            max_tokens=1024,\n",
        "            api_base=\"https://api.groq.com/openai/v1\",\n",
        "            api_key=GROQ_API_KEY1\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.tool_calls:\n",
        "            tool = response.choices[0].message.tool_calls[0]\n",
        "            result = {\n",
        "                \"tool\": tool.function.name,\n",
        "                \"args\": json.loads(tool.function.arguments),\n",
        "            }\n",
        "            result = json.dumps(result)\n",
        "        else:\n",
        "            result = response.choices[0].message.content\n",
        "\n",
        "    return result\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "class Action:\n",
        "    def __init__(self, name: str, function: Callable, description: str, parameters: Dict, terminal: bool = False):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "        self.terminal = terminal\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def execute(self, **args) -> Any:\n",
        "        return self.function(**args)\n",
        "\n",
        "class ActionRegistry:\n",
        "    def __init__(self):\n",
        "        self.actions = {}\n",
        "\n",
        "    def register(self, action: Action):\n",
        "        self.actions[action.name] = action\n",
        "\n",
        "    def get_action(self, name: str) -> [Action, None]:\n",
        "        return self.actions.get(name, None)\n",
        "\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        return list(self.actions.values())\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.items = []\n",
        "\n",
        "    def add_memory(self, memory: dict):\n",
        "        self.items.append(memory)\n",
        "\n",
        "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "        return self.items[:limit]\n",
        "\n",
        "    def copy_without_system_memories(self):\n",
        "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "        memory = Memory()\n",
        "        memory.items = filtered_items\n",
        "        return memory\n",
        "\n",
        "class Environment:\n",
        "    def execute_action(self, action: Action, args: dict) -> dict:\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return self.format_result(result)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool_executed\": False,\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    def format_result(self, result: Any) -> dict:\n",
        "        return {\n",
        "            \"tool_executed\": True,\n",
        "            \"result\": result,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        }\n",
        "\n",
        "class AgentLanguage:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def construct_prompt(self, actions: List[Action], environment: Environment, goals: List[Goal], memory: Memory) -> Prompt:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "class AgentFunctionCallingActionLanguage(AgentLanguage):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def format_goals(self, goals: List[Goal]) -> List:\n",
        "        sep = \"\\n-------------------\\n\"\n",
        "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
        "        return [{\"role\": \"system\", \"content\": goal_instructions}]\n",
        "\n",
        "    def format_memory(self, memory: Memory) -> List:\n",
        "        items = memory.get_memories()\n",
        "        mapped_items = []\n",
        "        for item in items:\n",
        "            content = item.get(\"content\", None)\n",
        "            if not content:\n",
        "                content = json.dumps(item, indent=4)\n",
        "            if item[\"type\"] == \"assistant\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            elif item[\"type\"] == \"environment\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            else:\n",
        "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "        return mapped_items\n",
        "\n",
        "    def format_actions(self, actions: List[Action]) -> [List, List]:\n",
        "        tools = [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": action.name,\n",
        "                    \"description\": action.description[:1024],\n",
        "                    \"parameters\": action.parameters,\n",
        "                },\n",
        "            } for action in actions\n",
        "        ]\n",
        "        return tools\n",
        "\n",
        "    def construct_prompt(self, actions: List[Action], environment: Environment, goals: List[Goal], memory: Memory) -> Prompt:\n",
        "        prompt = []\n",
        "        prompt += self.format_goals(goals)\n",
        "        prompt += self.format_memory(memory)\n",
        "        tools = self.format_actions(actions)\n",
        "        return Prompt(messages=prompt, tools=tools)\n",
        "\n",
        "    def adapt_prompt_after_parsing_error(self, prompt: Prompt, response: str, traceback: str, error: Any, retries_left: int) -> Prompt:\n",
        "        return prompt\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        try:\n",
        "            return json.loads(response)\n",
        "        except Exception as e:\n",
        "            return {\"tool\": \"terminate\", \"args\": {\"message\": response}}\n",
        "    # def parse_response(self, response: str) -> dict:\n",
        "    # #Parse LLM response into structured format by extracting JSON block\n",
        "    #   try:\n",
        "    #       return json.loads(response)\n",
        "    #   except Exception:\n",
        "    #       if not response.strip():\n",
        "    #           # Ask LLM to think again, don't terminate\n",
        "    #           return {\"tool\": \"noop\", \"args\": {}}\n",
        "    #       return {\n",
        "    #           \"tool\": \"terminate\",\n",
        "    #           \"args\": {\"message\": response}\n",
        "    #       }\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, goals: List[Goal], agent_language: AgentLanguage, action_registry: ActionRegistry, generate_response: Callable[[Prompt], str], environment: Environment):\n",
        "        self.goals = goals\n",
        "        self.generate_response = generate_response\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "        return self.agent_language.construct_prompt(actions.get_actions(), self.environment, goals, memory)\n",
        "\n",
        "    def get_action(self, response):\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation[\"tool\"])\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response: str) -> bool:\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return action_def.terminal\n",
        "\n",
        "    def set_current_task(self, memory: Memory, task: str):\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
        "\n",
        "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "        new_memories = [\n",
        "            {\"type\": \"assistant\", \"content\": response},\n",
        "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        for m in new_memories:\n",
        "            memory.add_memory(m)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "        return self.generate_response(full_prompt)\n",
        "\n",
        "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "        memory = memory or Memory()\n",
        "        self.set_current_task(memory, user_input)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "            print(\"Agent thinking...\")\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            print(f\"Agent Decision: {response}\")\n",
        "\n",
        "            action, invocation = self.get_action(response)\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "            print(f\"Action Result: {result}\")\n",
        "\n",
        "            self.update_memory(memory, response, result)\n",
        "\n",
        "            if self.should_terminate(response):\n",
        "                break\n",
        "\n",
        "        return memory\n",
        "\n",
        "# Setup code\n",
        "# goals = [\n",
        "#     Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n",
        "#     Goal(priority=1, name=\"Terminate\", description=\"Call terminate after reading files and show README\")\n",
        "# ]\n",
        "\n",
        "goals = [\n",
        "    Goal(priority=1, name=\"List Project Files\", description=\"List all project files ending with .py\"),\n",
        "    Goal(priority=1, name=\"Read All Files\", description=\"Read the content of each project file to gather information.\"),\n",
        "    Goal(priority=1, name=\"Generate README\", description=\"For each file, briefly summarize its purpose, main functions/classes, key logic, and any dependencies between files. Organize your findings clearly for quick codebase understanding and write the summary of python files into README (1).md file\"),\n",
        "    Goal(priority=1, name=\"Terminate\", description=\"Once README.md is created, terminate the session.\")\n",
        "]\n",
        "\n",
        "agent_language = AgentFunctionCallingActionLanguage()\n",
        "\n",
        "def read_project_file(name: str) -> str:\n",
        "    with open(name, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def list_project_files() -> List[str]:\n",
        "    return sorted([file for file in os.listdir(\".\") if file.endswith(\".py\")])\n",
        "\n",
        "def write_readme_file(content: str) -> str:\n",
        "    \"\"\"Writes the provided content to a README.md file in the current directory.\"\"\"\n",
        "    try:\n",
        "        with open(\"README (1).md\", \"w\") as file:\n",
        "            file.write(content)\n",
        "        return \"README.md file created successfully.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error writing README.md file: {str(e)}\"\n",
        "\n",
        "\n",
        "action_registry = ActionRegistry()\n",
        "action_registry.register(Action(\"list_project_files\", list_project_files, \"Lists project files.\", {}, terminal=False))\n",
        "action_registry.register(Action(\"read_project_file\", read_project_file, \"Reads project file.\", {\"type\": \"object\", \"properties\": {\"name\": {\"type\": \"string\"}}, \"required\": [\"name\"]}, terminal=False))\n",
        "action_registry.register(Action(\"terminate\", lambda message: f\"{message}\\nTerminating...\", \"Terminates session.\", {\"type\": \"object\", \"properties\": {\"message\": {\"type\": \"string\"}}, \"required\": []}, terminal=True))\n",
        "action_registry.register(Action(\n",
        "    name=\"write_readme\",\n",
        "    function=write_readme_file,\n",
        "    description=\"Generates README content based on project files.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"content\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"content\"]\n",
        "    },\n",
        "    terminal=True\n",
        "))\n",
        "\n",
        "\n",
        "environment = Environment()\n",
        "agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n",
        "\n",
        "user_input = \"Write readme.md file, which includes the summary of all the python files\"\n",
        "final_memory = agent.run(user_input)\n",
        "print(final_memory.get_memories())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lzx5jNMYXEze"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
